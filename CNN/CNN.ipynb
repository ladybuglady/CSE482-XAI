{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:51:16.255953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Attia et. al. model with 6-lead ECG Data\n",
    "# 6 leads are reduced to 2 independent leads\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ IMPORTS ~~~~~~~~~~~~~~~\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import concatenate,Activation,Dropout,Dense,ZeroPadding2D\n",
    "from keras.layers import Input,add,Conv2D, MaxPooling2D,Flatten,BatchNormalization,LSTM\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import zipfile\n",
    "from pandas import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from CNN_6lead_model_keras import ResNet18\n",
    "from pandas import *\n",
    "import json\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "# import numpy_indexed as npi\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import os, os.path\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import shap\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ CONNECT TO GPU ~~~~~~~~~~~~~~~\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "if os.environ.get(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    #Choose GPU 0 as a default if not specified (can set this in Python script that calls this)\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ DATA PREPROCESS ~~~~~~~~~~~~~~~\n",
    "def preprocess(X, y_labels):\n",
    "  # Change X dims for model compatibility\n",
    "  # expected shape=(None, 5000, 2, 1)\n",
    "  X = np.swapaxes(X,1,2)\n",
    "  X = np.expand_dims(X, axis=3)\n",
    "\n",
    "  # Change y dims to one-hot encoding, should be (300, 2)\n",
    "  y = to_categorical(y_labels, dtype =\"uint8\")\n",
    "\n",
    "  X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "  X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "  N_Val = y_valid.shape[0]\n",
    "  N_Train = y_train.shape[0]\n",
    "\n",
    "  print ('Training on : ' + str(N_Train) + ' and validating on : ' +str(N_Val))\n",
    "\n",
    "  n_classes = 2\n",
    "  return X_train, X_rem, y_train, y_rem, X_valid, X_test, y_valid, y_test, n_classes\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ DATA FETCH ~~~~~~~~~~~~~~~\n",
    "\n",
    "def combine_sets(afib_path, control_path, size=20000):\n",
    "  np.random.seed(777) # Lucky number 7. \n",
    "  \n",
    "  # Of these, select a random sample:\n",
    "  afib_ecgs =random.choices(os.listdir(afib_path), k=int(size)) # has to be hardcoded in for some reason??!?!?!\n",
    "\n",
    "  # Set up y values. These are all afib patients.\n",
    "  y_labels_afib = np.ones(int(size)) # an array of all 1's\n",
    "\n",
    "  # Now, let's get the healthy patients:\n",
    "  control_ecgs = random.choices(os.listdir(control_path), k=int(size))\n",
    "  y_labels_control = np.zeros(int(size))\n",
    "\n",
    "  # Concatenate the 2 arrays:\n",
    "  image_filenames = np.concatenate([afib_ecgs, control_ecgs])\n",
    "  y_labels = np.concatenate([y_labels_afib, y_labels_control]) #.to(device)\n",
    "\n",
    "  # Now randomize and make sure correct labels line up with ecgs:\n",
    "  random_indices = np.random.randint(low=0,high=int(size)*2-1,size = (int(size)*2,))\n",
    "  image_filenames = image_filenames[random_indices]\n",
    "  y_labels = y_labels[random_indices]\n",
    "\n",
    "  # Let's verify:\n",
    "  print(image_filenames[4])\n",
    "  print(y_labels[4])\n",
    "  print(image_filenames[4] in afib_ecgs) # if y-label is 1, then this should be true. if y-label is 0, should be false.\n",
    "\n",
    "  return image_filenames, y_labels\n",
    "\n",
    "\n",
    "def fetch_data(datatype, size=20000, load=True):\n",
    "\n",
    "  if datatype == 'spectrogram':\n",
    "    if load:\n",
    "      return preprocess(np.load(\"spectro_X.npy\")[0:3000], np.load(\"spectro_Y.npy\")[0:3000])\n",
    "    afib_path =  '/local1/CSE_XAI/CSE482-XAI/image_data_processing/control_ecgs_as_spectro/'\n",
    "    control_path = '/local1/CSE_XAI/CSE482-XAI/image_data_processing/afib_ecgs_as_spectro/'\n",
    "  else: \n",
    "    afib_path =  '../../../../../../../local1/CSE_XAI/CSE482-XAI/image_data_processing/control_ecgs_as_plots/'\n",
    "    control_path = '../../../../../../../local1/CSE_XAI/CSE482-XAI/image_data_processing/afib_ecgs_as_plots/'\n",
    "\n",
    "\n",
    "  image_filenames, Y = combine_sets(afib_path, control_path, size)\n",
    "\n",
    "\n",
    "  X = np.zeros((int(size*2), 300, 300))\n",
    "  counter = 0\n",
    "  for file in image_filenames:\n",
    "    \n",
    "    if counter %1000 == 0:\n",
    "      print(\"Retrieved files: \", counter)\n",
    "\n",
    "    try:\n",
    "      image = Image.open(afib_path + file)\n",
    "    except:\n",
    "      image = Image.open(control_path + file)\n",
    "\n",
    "    image = ImageOps.grayscale(image)\n",
    "\n",
    "    if datatype == 'spectrogram':\n",
    "\n",
    "      im = Image.open(\"/local1/CSE_XAI/CSE482-XAI/image_data_processing/afib_ecgs_as_spectro/\"+file)\n",
    "      im = ImageOps.grayscale(im)\n",
    "      im = im.crop((140, 140, 1800, 1400))\n",
    "      im = im.resize((300, 300), Image.ANTIALIAS)\n",
    "      \n",
    "      patient_X = np.asarray(im)\n",
    "\n",
    "    \n",
    "    X[counter] = patient_X\n",
    "    counter += 1\n",
    "  \n",
    "  print(\"saving data into numpy arrays...\")\n",
    "  \"\"\"\n",
    "  if datatype == 'spectrogram':\n",
    "    np.save(\"spectro_X.npy\", X)\n",
    "    np.save(\"spectro_Y.npy\", Y)\n",
    "  else:\n",
    "    np.save(\"plot_X.npy\", X)\n",
    "    np.save(\"plot_Y.npy\", Y)\n",
    "\n",
    "    \"\"\"\n",
    "  return preprocess(X, Y)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ TRAIN MODEL ~~~~~~~~~~~~~~~\n",
    "def train_model(X_train, X_rem, y_train, y_rem, X_valid, X_test, y_valid, y_test, n_classes, model_name):\n",
    "  \n",
    "  model = ResNet18(2)\n",
    "\n",
    "  opt0 = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.5)\n",
    "  model.compile(loss='categorical_crossentropy',  optimizer=opt0,  metrics=['accuracy'])\n",
    "\n",
    "  earlyStopCallback = EarlyStopping(monitor='val_loss', min_delta=0, patience=9,  mode='auto')\n",
    "  saveBestCallback = ModelCheckpoint(model_name+'weights_only_checkpoint.h5',monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "  reduceLR =ReduceLROnPlateau(monitor = 'val_loss',factor = 0.5,patience = 3,verbose=1,min_lr = 0.00001)\n",
    "  history = model.fit(X_train, y_train,validation_data=(X_valid, y_valid),epochs=5, batch_size=128, verbose=1, \n",
    "                      callbacks=[saveBestCallback,earlyStopCallback,reduceLR]) #class_weight=class_weight\n",
    "\n",
    "  \n",
    "  return model\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ CALCULATE TEST ACCURACY ~~~~~~~~~~~~~~~\n",
    "def get_test_acc(model, X_test, y_test):\n",
    "  score = model.evaluate(X_test, y_test, verbose = 0) \n",
    "\n",
    "  print('Test loss:', score[0]) \n",
    "  print('Test accuracy:', score[1])\n",
    "  print()\n",
    "  print(\"For reference, Attia model reports 83.3% test accuracy.\")\n",
    "  return score[1]\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ SAVE MODEL ~~~~~~~~~~~~~~~\n",
    "def save_model(model, name):\n",
    "  model.save(name)\n",
    "  print(\"Saved model to \", name)\n",
    "\n",
    "def load_model(filename, input_size):\n",
    "  model = ResNet18(2)\n",
    "  model.build(input_shape=input_size)\n",
    "  model.load_weights(filename)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_5209.png\n",
      "1.0\n",
      "True\n",
      "Retrieved files:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved files:  1000\n",
      "Retrieved files:  2000\n",
      "Retrieved files:  3000\n",
      "Retrieved files:  4000\n",
      "Retrieved files:  5000\n",
      "saving data into numpy arrays...\n",
      "Training on : 4800 and validating on : 600\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"-f\", \"--full\", help=\"If you would like to use the full dataset (not recommended) use --full, otherwise, sample is used.\", action=\"store_true\")\n",
    "#parser.add_argument(\"-s\", \"--spectrogram\", help=\"Use this tag to use spectrogram images instead of plots.\", action=\"store_true\")\n",
    "#parser.add_argument(\"-l\", \"--load_data\",help=\"Use this load the data from the npy files.\", action=\"store_true\")\n",
    "#args = parser.parse_args()\n",
    "size = 3000\n",
    "datatype = \"plot\"\n",
    "#if args.full:\n",
    "#  size = 'full'\n",
    "#if args.spectrogram:\n",
    "datatype = \"spectrogram\"\n",
    "\n",
    "model_name = 'CNN_6lead_'+str(size)+'_dataset_'\n",
    "X_train, X_rem, y_train, y_rem, X_valid, X_test, y_valid, y_test, n_classes = fetch_data(datatype, size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <CNN_6lead_model_keras.ResnetBlock object at 0x7fcc5d54bc40>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <CNN_6lead_model_keras.ResnetBlock object at 0x7fcc5d54bc40>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:58:40.960079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 10:58:40.960744: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  438.0730617046356\n"
     ]
    }
   ],
   "source": [
    "# model = train_model(X_train, X_rem, y_train, y_rem, X_valid, X_test, y_valid, y_test, n_classes, model_name)\n",
    "\n",
    "#test_acc = get_test_acc(model, X_test, y_test)\n",
    "#model_name += '_'+str(test_acc)[2:]\n",
    "\n",
    "modelfile = modelfile = '/local1/CSE_XAI/CSE482-XAI/CNN/CNN_6lead_3000_dataset_weights_only_checkpoint.h5'\n",
    "input_size = (10, 224, 224, 1)\n",
    "model = load_model(modelfile, input_size)\n",
    "#model = load_model(modelfile, input_size)\n",
    "\n",
    "#save_model(model, model_name)\n",
    "end_time = time.time()\n",
    "print(\"Elapsed time: \", str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 300, 300, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'afib': array([[[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [253.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]]]), 'normal': array([[[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [253.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[255.],\n",
      "        [255.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]]])}\n"
     ]
    }
   ],
   "source": [
    "# class label list\n",
    "class_names = ['normal', 'afib']\n",
    "# example image for each class\n",
    "images_dict = dict()\n",
    "\n",
    "images_dict[class_names[0]] = X_train[0]\n",
    "images_dict[class_names[1]] = X_train[4]\n",
    "\n",
    "images_dict = dict(sorted(images_dict.items()))\n",
    "print(images_dict)\n",
    "    \n",
    "# example image for each class for test set\n",
    "x_test_dict = dict()\n",
    "\n",
    "x_test_dict[class_names[0]] = X_test[0]\n",
    "x_test_dict[class_names[1]] = X_test[2]\n",
    "\n",
    "# order by class\n",
    "x_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
    "x_test_each_class = np.asarray(x_test_each_class)\n",
    "# Compute predictions\n",
    "\n",
    "predictions = model(x_test_each_class.reshape((2, 300, 300, 1)))\n",
    "predicted_class = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot actual and predicted class\n",
    "def plot_actual_predicted(images, pred_classes):\n",
    "  fig, axes = plt.subplots(1, 11, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "  \n",
    "  # plot\n",
    "  ax = axes[0]\n",
    "  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n",
    "  ax.set_title(\"Base reference\")\n",
    "  ax.set_axis_off()\n",
    "  ax.imshow(dummy_array, interpolation='nearest')\n",
    "  # plot image\n",
    "  for k,v in images.items():\n",
    "    ax = axes[k+1]\n",
    "    ax.imshow(v, cmap=plt.cm.binary)\n",
    "    ax.set_title(f\"True: %s \\nPredict: %s\" % (class_names[k], class_names[pred_classes[k]]))\n",
    "    ax.set_axis_off()\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  3200      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  multiple                  74368     \n",
      "                                                                 \n",
      " resnet_block_1 (ResnetBlock  multiple                 74368     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_2 (ResnetBlock  multiple                 231296    \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_3 (ResnetBlock  multiple                 296192    \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_4 (ResnetBlock  multiple                 921344    \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_5 (ResnetBlock  multiple                 1182208   \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_6 (ResnetBlock  multiple                 3677696   \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_7 (ResnetBlock  multiple                 4723712   \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (G  multiple                 0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,185,666\n",
      "Trainable params: 11,176,066\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 128, 128, 1), found shape=(500, 300, 300, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m background \u001b[39m=\u001b[39m X_test[:\u001b[39m500\u001b[39m]\n\u001b[1;32m      7\u001b[0m test_images \u001b[39m=\u001b[39m X_test[\u001b[39m500\u001b[39m:\u001b[39m504\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m e \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mDeepExplainer(newModel, background)\n\u001b[1;32m     10\u001b[0m shap_values \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mshap_values(test_images)\n\u001b[1;32m     12\u001b[0m shap_numpy \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mswapaxes(np\u001b[39m.\u001b[39mswapaxes(s, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m shap_values]\n",
      "File \u001b[0;32m~/anaconda3/envs/momo/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py:84\u001b[0m, in \u001b[0;36mDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     81\u001b[0m         framework \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplainer \u001b[39m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[39melif\u001b[39;00m framework \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplainer \u001b[39m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[0;32m~/anaconda3/envs/momo/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:162\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m    159\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         \u001b[39m#if type(self.model)is tuple:\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         \u001b[39m#    self.fModel(cnn.inputs, cnn.get_layer(theNameYouWant).outputs)\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata), \u001b[39m0\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_between_tensors(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output\u001b[39m.\u001b[39mop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/momo/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/momo/lib/python3.9/site-packages/keras/engine/input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[0;32m--> 295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    297\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 128, 128, 1), found shape=(500, 300, 300, 1)"
     ]
    }
   ],
   "source": [
    "newInput = Input(batch_shape=(1,128,128,1))\n",
    "newOutputs = model(newInput)\n",
    "newModel = Model(newInput, newOutputs)\n",
    "newModel.set_weights(model.get_weights())\n",
    "\n",
    "background = X_test[:500]\n",
    "test_images = X_test[500:504]\n",
    "\n",
    "e = shap.DeepExplainer(newModel, background)\n",
    "shap_values = e.shap_values(test_images)\n",
    "\n",
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)\n",
    "\n",
    "# plot the feature attributions\n",
    "shap.image_plot(shap_numpy, -test_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
